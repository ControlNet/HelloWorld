{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Perceptron\n",
    "\n",
    "Environment: R 3.6.1 and Jupyter notebook\n",
    "\n",
    "Libraries used:\n",
    "* dplyr\n",
    "* Matrix\n",
    "* ggplot2\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, it is to implement a multi-class perceptron to 3 classes for classification and some visualizations against different learning rates. The algorithm as a class `Perceptron` is implemented with more generic purpose. The `Perceptron` can be trained with any batch_size, SGD or BGD, and also it can be trained to classify the binary classes data and multiple classes data.\n",
    "\n",
    "For binary perceptron, there is one classifier to divide 2 classes. As multi-class perceptron, 3 set of weights are required to classify each class, and then in activation function to find which one is predicted highest to decide the data belong which class.\n",
    "\n",
    "The algorithm of multi-class perceptron is shown below.\n",
    "* Initialise the weight vectors randomly $w_1$,..,$w_K$\n",
    "* For $n$ = 1 to N do:\n",
    "    * y = argmaxk $w_k ... x_n$\n",
    "    * If $y_n \\ne t_n$ do\n",
    "        * $w_{ğ‘¦ğ‘›} \\leftarrow ğ’˜_{ğ‘¦ğ‘›} âˆ’ Î·ğ’™_ğ‘› $\n",
    "        * $w_{ğ‘¡ğ‘›} \\leftarrow ğ’˜_{ğ‘¡ğ‘›} + Î·ğ’™_ğ‘› $\n",
    "\n",
    "More details about the implementation like vectorization and algorithms will be explained in the section `Implementation`.\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n"
     ]
    }
   ],
   "source": [
    "options(warn=-1)\n",
    "\n",
    "library(dplyr)\n",
    "library(Matrix)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data <- function(fname, sc) {\n",
    "  data <- read.csv(file = fname, head = TRUE, sep = \",\")\n",
    "  nr = dim(data)[1]\n",
    "  nc = dim(data)[2]\n",
    "  x = data[1:nr, 1:(nc - 1)]\n",
    "  y = data[1:nr, nc]\n",
    "  if (isTRUE(sc)) {\n",
    "    x = scale(x)\n",
    "    y = scale(y)\n",
    "  }\n",
    "  return(list(\"x\" = x, \"y\" = y))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data <- read_data(\"train4.csv\", FALSE)\n",
    "x_train <- train_data$x\n",
    "y_train <- train_data$y\n",
    "\n",
    "test_data <- read_data(\"test4.csv\", FALSE)\n",
    "x_test <- test_data$x\n",
    "y_test <- test_data$y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Perceptron\n",
    "\n",
    "The implementation of `Perceptron` class is the main part of this notebook. The vectorization is widely used in the algorithm to implement a perceptron for both binary-class and multi-class classification. The multi-class perceptron can be extended by the binary-class. So, the binary-class perceptron will be introduced first. \n",
    "\n",
    "In the implementation, for easier programming of vectorization, the intercept value of the weights are divided as $b$ , and the rest of weights are notated as $w_n$.\n",
    "\n",
    "### Binary-class Perceptron\n",
    "\n",
    "Annotations:\n",
    "* $w_n$: The n-th weight.\n",
    "* $W$: The weight vector contains n weights, with shape $(n \\times 1)$\n",
    "* $b$: The intercept.\n",
    "* $x_n^{(m)}$: The n-th predictor of m-th row.\n",
    "* $x^{(m)}$: The predictor row vector of m-th row.\n",
    "* $X$: The predictor matrix with shape $(m \\times n)$\n",
    "* $y^{(m)}$: The m-th row prediction.\n",
    "* $Y$: The column vector of predictions with shape $(m \\times 1)$.\n",
    "* $f$: The activation function for transform the positive result as $1$ and negative as $-1$ .\n",
    "\n",
    "For binary classification, the weight $w_n$ and intercept $b$ are used to computing the predicted value of $x_n^{(m)}$ as,\n",
    "$$\\begin{align}\n",
    "y^{(m)} &= f\\left(\\sum_{i=1}^{n}{w_i x_i^{(m)}} + b\\right) \\\\\n",
    "&= f\\left(w_1 x_1^{(m)} + w_2 x_2^{(m)} + \\dots + w_n x_n^{(m)} + b\\right)\n",
    "\\end{align}$$\n",
    "\n",
    "So, the computation for predicting m-th row label can be vectorized as below,\n",
    "$$\\begin{align}\n",
    "y^{(m)} &= f\\left(\\bigl(\\begin{matrix} x_1^{(m)} & x_2^{(m)} & \\cdots & x_n^{(m)} \\end{matrix}\\bigr) \\cdot\n",
    "\\begin{pmatrix} w_1\\\\ w_2\\\\ \\vdots\\\\ w_n \\end{pmatrix} + b\\right) \\\\\n",
    "&= f\\left(x^{(m)} \\cdot W + b\\right)\n",
    "\\end{align}$$\n",
    "\n",
    "The vectorization below can reduce one for-loop, and use just one matrix multiplication to calculate the $y^{(m)}$ for one row. And next, the calculation of multiple rows can be vectorized as well. The $y$ for each row can be stack as a column vector $Y$ with shape $m \\times 1$.\n",
    "\n",
    "$$\\begin{align}\n",
    "Y = \\begin{pmatrix} y^{(1)}\\\\ y^{(2)}\\\\ \\vdots\\\\ y^{(m)} \\\\ \\end{pmatrix} \n",
    " &= f\\left(\\begin{pmatrix} x_1^{(1)} & x_2^{(1)} & \\cdots & x_n^{(1)}\\\\ x_1^{(2)} & x_2^{(2)} & \\cdots & x_n^{(2)}\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\  x_1^{(m)} & x_2^{(m)} & \\cdots & x_n^{(m)} \\end{pmatrix} \\begin{pmatrix} w_1\\\\ w_2\\\\ \\vdots\\\\ w_n \\end{pmatrix} + \n",
    "\\begin{pmatrix} b\\\\ b\\\\ \\vdots\\\\ b \\end{pmatrix} \\right) \\\\\n",
    " &= f\\left(X \\cdot W + b\\right)\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "With further vectorization, only one matrix multiplication is needed to calculate all y-value for whole dataset. In R language, the vectorized computation is far more faster than for-loop. As the vectroziation is linearly, the gradient of W is also easy to calculate. With learning rate $\\eta$. From the pdf, the gradient descent can be applied as,\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\left\\{\\begin{array}{} \n",
    "W &\\leftarrow W + \\eta \\cdot X^T Y \\mbox{,}  \\\\\n",
    "b &\\leftarrow b + \\eta \\cdot Y \n",
    "\\end{array}\\right.\\\\\n",
    "\\mbox{The X and Y only contains the misclassified rows}\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class Perceptron\n",
    "\n",
    "Annotation:\n",
    "* $w_{nk}$: The n-th weight for k-th classifier\n",
    "* $w_{k}$: The weights vector for k-th classifier with shape $(1 \\times k)$\n",
    "* $W$: The weights matrix contains k classifiers with each having n weights, with shape $(n \\times k)$\n",
    "* $b_k$: The intercept for k-th classifier.\n",
    "* $B$: The intercepts vector containing k intercepts with shape $(1 \\times k)$.\n",
    "* $x_n^{(m)}$: The n-th predictor of m-th row.\n",
    "* $x^{(m)}$: The predictor row vector of m-th row with shape $(1 \\times n)$.\n",
    "* $X$: The predictor matrix with shape $(m \\times n)$\n",
    "* $y_k^{(m)}$: The m-th row y-value prediction for k-th class.\n",
    "* $y^{(m)}$: The y-value row vector for the m-th row shape $(1 \\times k)$.\n",
    "* $Y$: The matrix of y-value with shape $(m \\times k)$.\n",
    "* $f$: The activation function for transform the vector result to find the maximum to get the label.\n",
    "\n",
    "For the number of class is larger than 3, multiple binary-class classifiers with weights are needed. As the linear algebra has favorable generalization for linear computations. The similar method of vectorization can be applied for multi-class perceptron as well.\n",
    "\n",
    "The main different of multi-class perceptron from binary-class is the multiple weights vector is needed. Therefore, they can be vectorized by stacking as a matrix with shape $(n \\times k)$ like below,\n",
    "\n",
    "$$\\begin{align}\n",
    "W = \\left(\\begin{matrix} w_1 & w_2 & \\cdots & w_k \\end{matrix}\\right) = \\begin{pmatrix}\n",
    "w_{11} & w_{21} & \\cdots & w_{k1}\\\\ \n",
    "w_{21} & w_{22} & \\cdots & w_{k2}\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\ \n",
    "w_{m1} & w_{2m} & \\cdots & w_{kn}\n",
    "\\end{pmatrix}\n",
    "\\end{align}$$\n",
    "\n",
    "Then, the similar method can be applied in prediction the y-value. Also, as there are k classifiers, there is a y vector formed by k y-values.\n",
    "\n",
    "$$\\begin{align} \n",
    "Y = \\begin{pmatrix} y^{(1)}\\\\ y^{(2)}\\\\ \\vdots\\\\ y^{(m)} \\\\ \\end{pmatrix} = \\begin{pmatrix} \n",
    "y_1^{(1)} & y_2^{(1)} & \\cdots & y_k^{(1)}\\\\ y_1^{(2)} & y_2^{(2)} & \\cdots & y_k^{(2)}\\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\ y_1^{(m)} & y_2^{(m)} & \\cdots & y_k^{(n)}\n",
    "\\end{pmatrix}\n",
    "\\end{align}$$\n",
    "\n",
    "Also, the $B$ vector combined the k intercepts for each classifier, so\n",
    "$$\n",
    "B = \\left(\\begin{matrix} b_1 & b_2 & \\cdots & b_k \\end{matrix}\\right)\n",
    "$$\n",
    "\n",
    "From the equations got in binary-class perceptron, the $Y$ can be calculated from $X$, $W$ and $B$ as,\n",
    "\n",
    "$$\n",
    "Y = f(XW + B)\n",
    "$$\n",
    "\n",
    "Also,\n",
    "\n",
    "$$w_{ğ‘¦ğ‘›} \\leftarrow ğ’˜_{ğ‘¦ğ‘›} âˆ’ Î·ğ’™_ğ‘› $$\n",
    "$$w_{ğ‘¡ğ‘›} \\leftarrow ğ’˜_{ğ‘¡ğ‘›} + Î·ğ’™_ğ‘› $$\n",
    "\n",
    "Besides, the gradient of $W$ and $B$ for error function can be,\n",
    "$$\\begin{align}\n",
    "&\\nabla{E(W)} = -X^{T}Y \\\\\n",
    "&\\nabla{E(B)} = -Y\n",
    "\\end{align}$$\n",
    "\n",
    "Therefore, the matrix$Y$ can be considered a mask, which is implemented to combined the formulas. When the the prediction is true, the mask is 1, else -1. This mask can perform the difference of the add/minus in the above training process. Therefore, the it can be considered as \n",
    "$$W \\leftarrow W - \\eta \\nabla{E(W)}$$\n",
    "$$B \\leftarrow B - \\eta \\nabla{E(B)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron class\n",
    "\n",
    "From the formula $Y = f(XW + B)$, the class `Perceptron` can be implemented as the similar format with `KNNRegressor` in `knn_regressor.ipynb`. There are many fields and methods in the class. The functionality of them are shown below.\n",
    "\n",
    "* fields:\n",
    "    * `w`: The coefficients matrix $W$ of $X$, which has been mentioned above.\n",
    "    * `b`: The intercept vector $B$ of the model.\n",
    "    * `history`: A dataframe to store the trends of weights and errors.\n",
    "    \n",
    "* methods:\n",
    "    * `fit`: Train the model by given training dataset.\n",
    "    * `predict`: A method to predict label $y$ from given dataset $X$ .\n",
    "    * `preprocess`: A method for intializing parameters, shuffle data and split as batches.\n",
    "    * `step_activation`: The activation function can transfer float(double) as 1 or -1 by its potitive and negative.\n",
    "    * `max_activation`: The activation function for predict the label by the results of classifiers (reversed one hot).\n",
    "    * `loss`: A function for calculate the error.\n",
    "    * `get_history_names`: A function for generate column names of history data frame\n",
    "    * `to_batches`: A function for split data as batches\n",
    "    \n",
    "For more details of definition of this class, please refer to the codes below and their comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perceptron <- setRefClass(\"Perceptron\", fields = list(w = \"Matrix\", b = \"numeric\", history = \"data.frame\"), \n",
    "                          methods = list(\n",
    "    fit = function(x, y, epochs, batch_size = 1, validation_data = NULL, learning_rate_decay = 1,\n",
    "                   learning_rate = 0.01, shuffle = TRUE, history_per_step = FALSE) {\n",
    "      # divide the data as batches\n",
    "      batches <- .self$preprocess(x, y, batch_size, shuffle)\n",
    "\n",
    "      fit_each_epoch <- function(epoch) {\n",
    "        fit_each_batch <- function(batch) {\n",
    "          # reformat the x y dataframe as matrix for computation\n",
    "          if (batch_size == 1) {\n",
    "            x_batch <- t(Matrix(batch$x))\n",
    "            y_batch <- t(Matrix(batch$y))\n",
    "          } else {\n",
    "            x_batch <- Matrix(batch$x)\n",
    "            y_batch <- Matrix(batch$y)\n",
    "          }\n",
    "          # predict the data is belonged to which class\n",
    "          y_hat <- .self$predict(x_batch, .self$max_activation)\n",
    "          # inverse one hot to find real labels\n",
    "          y_target <- .self$max_activation(y_batch)\n",
    "          # locate the misclassified index\n",
    "          misclassified_index <- (y_hat != y_target) %>% as.vector\n",
    "          # define a mask for calculating the gradient  \n",
    "          y_mask <- y_batch - .self$predict(x_batch, .self$step_activation)\n",
    "          # training, if all the prediction match, skip.\n",
    "          if (sum(misclassified_index) != 0) {\n",
    "            # vectorized calculation of the gradient by grad(w) = xy, and grad(b) = y\n",
    "            grad_w <- (-1 * t(x_batch) %*% y_mask) / batch_size\n",
    "            grad_b <- -1 * colMeans(y_mask %>% Matrix) * batch_size / sum(misclassified_index)\n",
    "\n",
    "            # apply the gradient descent\n",
    "            .self$w <- .self$w - learning_rate * grad_w\n",
    "            .self$b <- .self$b - learning_rate * grad_b\n",
    "          }\n",
    "\n",
    "          # generate history data for weights and error of given test data\n",
    "          if (is.null(validation_data)) c(.self$b, as.vector(.self$w))\n",
    "          else {\n",
    "            x_test <- validation_data[[1]]\n",
    "            y_test <- validation_data[[2]]\n",
    "            test_error <- .self$loss(x_test, y_test)\n",
    "            # stack the b and w, as the weights history for output\n",
    "            weights <- rbind(.self$b, .self$w)\n",
    "            # flatten the matrix as a vector and concat the test_error for output\n",
    "            c(as.vector(weights), test_error)\n",
    "          }\n",
    "        }\n",
    "        # if the learning_rate_decay is set,\n",
    "        # here it can apply learning rate decay.\n",
    "        if (learning_rate_decay != 1) {\n",
    "          learning_rate <<- learning_rate * learning_rate_decay\n",
    "        }\n",
    "        # apply the function above and return the history of this epoch\n",
    "        batch_history <- lapply(batches, fit_each_batch)\n",
    "        # output the history by each epoch or by each step(mini-batch)\n",
    "        if (history_per_step) batch_history\n",
    "        else batch_history[[length(batch_history)]]\n",
    "      }\n",
    "      # reformat the history data frame\n",
    "      if (history_per_step) {\n",
    "        # get history from training on each epoch, and combine as a data frame\n",
    "        weight_history <- 1:epochs %>% lapply(fit_each_epoch) %>%\n",
    "          unlist(recursive = FALSE) %>% Reduce(f = rbind) %>% as.data.frame\n",
    "        # generate column names and set\n",
    "        col_names <- c(\"step\", .self$get_history_names(x, y, validation_data))\n",
    "        # add step/epoch and colnames for the history data\n",
    "        .self$history <- cbind(1:nrow(weight_history), weight_history) %>% `colnames<-`(col_names)\n",
    "        .self\n",
    "      } else {\n",
    "        # reformat the history data if only logged on epoch\n",
    "        weight_history <- as.data.frame(t(sapply(1:epochs, fit_each_epoch)))\n",
    "        col_names <- c(\"epoch\", .self$get_history_names(x, y, validation_data))\n",
    "        .self$history <- cbind(1:epochs, weight_history) %>% `colnames<-`(col_names)\n",
    "        .self\n",
    "      }\n",
    "    },\n",
    "\n",
    "    predict = function(x, activation) {\n",
    "      if (class(x) == \"data.frame\") x <- x %>% data.matrix %>% Matrix\n",
    "      else if (class(x) == \"numeric\") x <- x %>% Matrix %>% t\n",
    "      # broadcast b\n",
    "      b <- .self$b %>%\n",
    "        rep(times = nrow(x)) %>%\n",
    "        Matrix(nrow = nrow(x), byrow = TRUE)\n",
    "      # predict the Z as XW+B by vectorization computation\n",
    "      z <- x %*% .self$w + b\n",
    "      # calculate Y_hat = f(Z)  \n",
    "      activation(z)\n",
    "    },\n",
    "\n",
    "    preprocess = function(x, y, batch_size, shuffle = TRUE) {\n",
    "      # this function is for preprocessing the data frame input\n",
    "      x_len <- nrow(x)\n",
    "      if (!class(y) %in% c(\"data.frame\", \"matrix\", \"Matrix\")) y <- Matrix(y)\n",
    "      n_classes <- ncol(y)\n",
    "      # if fit in the first time, initialize the weights\n",
    "      if (.self$w %>% length == 0) {\n",
    "        .self$w <- Matrix(runif(ncol(x) * n_classes), ncol = n_classes)\n",
    "        .self$b <- runif(n_classes)\n",
    "      }\n",
    "      # if shuffle applied, shuffle the data\n",
    "      if (shuffle) {\n",
    "        index <- sample(1:x_len, x_len, replace = FALSE)\n",
    "        x <- x[index,]\n",
    "        y <- y[index,]\n",
    "      }\n",
    "      # divide the data\n",
    "      batches <- .self$to_batches(x, y, batch_size)\n",
    "      batches\n",
    "    },\n",
    "\n",
    "    step_activation = function(z) {\n",
    "      # this activation function input float(double) numbers, and return -1 or 1\n",
    "      activation_f <- function(each_z) {\n",
    "        if (each_z >= 0) 1\n",
    "        else -1 }\n",
    "      apply(z, 2, function(row) sapply(row, activation_f))\n",
    "    },\n",
    "\n",
    "    max_activation = function(z) {\n",
    "      # this activation function return the prediction of class with maximum value\n",
    "      if (ncol(Matrix(z)) != 1) apply(z, 1, which.max)\n",
    "      # if the model is for binary classification, use the step_activation for the output\n",
    "      else .self$step_activation(z)\n",
    "    },\n",
    "\n",
    "    loss = function(x, y) {\n",
    "      # this function is for computing the loss with the x y data given\n",
    "      y_hat <- .self$predict(x, activation = .self$max_activation)\n",
    "      y_true <- {\n",
    "        if (ncol(Matrix(y)) != 1) .self$max_activation(y)\n",
    "        else y\n",
    "      }\n",
    "      misclassified_index <- y_true != y_hat\n",
    "      sum(misclassified_index) / nrow(x)\n",
    "    },\n",
    "\n",
    "    get_history_names = function(x, y, validation_data = NULL) {\n",
    "      # this function for generate the column names of history data\n",
    "      classes_n <- ncol(Matrix(y))\n",
    "      # generate weight column names\n",
    "      col_names <- {\n",
    "        if (classes_n == 1) {\n",
    "          w_names <- sapply(1:ncol(x), function(i) paste0(\"w\", i))\n",
    "          c(\"b\", w_names)\n",
    "        } else {\n",
    "          comb_names <- NULL\n",
    "          for (class_n in 1:classes_n) {\n",
    "            w_names <- sapply(1:ncol(x), function(i) paste0(\"c\", class_n, \"w\", i))\n",
    "            comb_names <- c(comb_names, paste0(\"c\", class_n, \"b\"), w_names)\n",
    "          }\n",
    "          comb_names\n",
    "        }\n",
    "      }\n",
    "      # generate test_error column names if needed\n",
    "      if (is.null(validation_data)) col_names\n",
    "      else c(col_names, \"test_error\")\n",
    "    },\n",
    "\n",
    "    to_batches = function(x, y, batch_size) {\n",
    "      # this function is for divide the data as batches\n",
    "      # as the batches are not divided equally, so there are complete batches,\n",
    "      # and a residual batch.\n",
    "      x <- as.matrix(x)\n",
    "      y <- as.matrix(y)\n",
    "      x_nrow <- nrow(x)\n",
    "      # the number of complete batches\n",
    "      complete_batch_num <- floor(x_nrow / batch_size)\n",
    "      # The last row of complete batches\n",
    "      complete_nrow <- complete_batch_num * batch_size\n",
    "      # locate the residual part\n",
    "      if (complete_nrow == x_nrow) {\n",
    "        x_residual <- NULL\n",
    "        y_residual <- NULL\n",
    "        batch_nums <- complete_batch_num\n",
    "      } else {\n",
    "        x_residual <- x[(complete_nrow + 1):x_nrow,]\n",
    "        y_residual <- y[(complete_nrow + 1):x_nrow,]\n",
    "        batch_nums <- complete_batch_num + 1\n",
    "      }\n",
    "      # get residual batch data\n",
    "      residual_nrow <- x_nrow - complete_nrow\n",
    "      if (residual_nrow == 1) {\n",
    "        x_residual <- t(x_residual)\n",
    "        y_residual <- t(y_residual)\n",
    "      }\n",
    "      # locate and get other batches\n",
    "      lapply(1:batch_nums, function(i) {\n",
    "        start_index <- (i - 1) * batch_size + 1\n",
    "        if (start_index + batch_size - 1 <= x_nrow) {\n",
    "          list(x = x[start_index:(start_index + batch_size - 1),],\n",
    "               y = y[start_index:(start_index + batch_size - 1),])\n",
    "        } else {\n",
    "          list(x = x_residual, y = y_residual)\n",
    "        }\n",
    "      })\n",
    "    }\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the labels\n",
    "\n",
    "As the labels are factors `C1`, `C2` and `C3`, the labels need to be one hot encoded to a vector which indecates the related label is $1$ and others are $-1$. For example, the $y$ = `C2` label will be encoded as $y = \\left(\\begin{matrix} -1 & 1 & -1 \\end{matrix}\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_one_hot <- function(y, classes = unique(y)) {\n",
    "  1:length(classes) %>% \n",
    "    lapply(FUN = function(i) ifelse(y == classes[i], 1, -1) %>% matrix) %>%\n",
    "    Reduce(f = cbind)\n",
    "}\n",
    "\n",
    "y_test_onehot <- perceptron_one_hot(y_test)\n",
    "y_train_onehot <- perceptron_one_hot(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the perceptrons\n",
    "\n",
    "The 2 models trained below are all same except the learning rate. One is 0.01 and another is 0.09."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time comsumption: about 50 seconds\n",
    "set.seed(5201)\n",
    "# train 2 models, with 220 epochs, 5 batch-size, 0.97 learning rate decay and shuffle the data.\n",
    "# the learning rate are 0.01 and 0.09.\n",
    "perceptron1 <- Perceptron()$fit(x_train, y_train_onehot, epoch = 160, batch_size = 5, learning_rate_decay = 0.97,\n",
    "                               validation_data = list(x_test, y_test_onehot),\n",
    "                               learning_rate = 0.01, shuffle = TRUE, history_per_step = TRUE)\n",
    "\n",
    "perceptron2 <- Perceptron()$fit(x_train, y_train_onehot, epoch = 160, batch_size = 5, learning_rate_decay = 0.97,\n",
    "                               validation_data = list(x_test, y_test_onehot),\n",
    "                               learning_rate = 0.09, shuffle = TRUE, history_per_step = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "In the visualization section, the plot needed to be visualized is the trend plot of test error against mini-batches, which is counted as step in the `Perceptron` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reformat the data frame for plot\n",
    "error_df <- cbind(perceptron1$history$step, perceptron1$history$test_error, perceptron2$history$test_error) %>%\n",
    "  as.data.frame %>% `colnames<-`(c(\"step\", \"model1\", \"model2\"))\n",
    "\n",
    "# plot\n",
    "ggplot(error_df) + \n",
    "    geom_line(mapping = aes(x = step, y = model2, color = \"learning rate = 0.09\"), alpha = 0.7) +\n",
    "    geom_line(mapping = aes(x = step, y = model1, color = \"learning rate = 0.01\"), alpha = 0.7) +\n",
    "    ggtitle(\"The test error against the mini-batch for 2 learning rates\") +\n",
    "    xlab(\"mini-batch\") + ylab(\"test error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain:\n",
    "\n",
    "The training with learning rate = 0.09 has more significant fluctuation than learning rate = 0.01. It is because the training process with larger learning rate causes overshooting easier. So, when the learning rate is 0.09, the training process is not stable compared with the model with learning rate = 0.01 .\n",
    "\n",
    "With the learning rate decay, the model training process can train the weights with decreasing learning rate which is beneficial for the overshotting problem. As for the speed of training, the number of mini-batches of training model of learning rate = 0.1 to stable situation is fewer than the model with learning rate = 0.09, which means the learning rate = 0.1 is faster than learning rate = 0.9 .\n",
    "\n",
    "In the end of the models training, both of them are keeping stable, but the test errors are not at 0. It is because the training error has been 0, so there is no gradient to train the weights, leading to a stable situation in the end of training. The distribution of train and test data is not totally same, so it not means the best model for training data is also the best for test data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
